Ninfa - IA Generativa com Mem√≥ria Persistente

![alt text](https://img.shields.io/badge/License-MIT-blue.svg)


![alt text](https://img.shields.io/badge/.NET-8.0-blueviolet)


![alt text](https://img.shields.io/badge/Status-Em%20Desenvolvimento-green)

Ninfa √© um projeto de Intelig√™ncia Artificial Generativa que vai al√©m da simples predi√ß√£o de texto. √â uma implementa√ß√£o de um agente de IA com um "c√©rebro" (uma rede neural LSTM customizada) e uma "mem√≥ria de longo prazo" (uma base de conhecimento persistente em disco). O sistema √© projetado para aprender, refletir, adquirir novo conhecimento em tempo real e evoluir a partir de suas intera√ß√µes.
Sum√°rio

    Vis√£o Geral

    Principais Funcionalidades

    Arquitetura do Sistema

        Diagrama de Fluxo

        An√°lise dos Componentes

            1. O N√∫cleo Generativo (O C√©rebro)

            2. A Mem√≥ria Virtual Persistente (A Base de Conhecimento)

            3. A Camada de Servi√ßos (As Fun√ß√µes Cognitivas)

            4. O Host da Aplica√ß√£o (O Corpo)

    Como Come√ßar

        Pr√©-requisitos

        Instala√ß√£o e Configura√ß√£o

    Como Usar

        Modo 1: Executando a API Web

        Modo 2: Executando o Treinamento

    Endpoints da API

    Roteiro de Desenvolvimento (Roadmap)

Vis√£o Geral

Este projeto implementa uma rede neural LSTM (Long Short-Term Memory) capaz de gerar texto. Seu principal diferencial √© a integra√ß√£o com um sistema de mem√≥ria customizado que permite √† IA:

    Armazenar conhecimento de forma persistente em um arquivo de mem√≥ria virtual.

    Refletir sobre a necessidade de novas informa√ß√µes com base nos prompts do usu√°rio.

    Adquirir conhecimento de fontes externas (APIs da OpenAI e Google).

    Internalizar o novo conhecimento atrav√©s de um micro-treinamento (fine-tuning).

    Adaptar-se dinamicamente, expandindo seu pr√≥prio vocabul√°rio e a arquitetura da rede neural em tempo de execu√ß√£o.

Principais Funcionalidades

    üß† Motor LSTM Customizado: Rede neural implementada do zero em C#, incluindo backpropagation.

    üíæ Mem√≥ria Virtual Persistente: Uma √°rvore bin√°ria de busca baseada em arquivo, que atua como uma base de conhecimento n√£o-vol√°til.

    üåê Aquisi√ß√£o de Conhecimento em Tempo Real: Conecta-se a APIs externas para buscar informa√ß√µes atualizadas quando seu conhecimento interno √© insuficiente.

    üìà Aprendizado Cont√≠nuo: Capacidade de "internalizar" novas informa√ß√µes, ajustando os pesos da rede com uma baixa taxa de aprendizado.

    üß© Vocabul√°rio Din√¢mico: Expande seu vocabul√°rio e adapta as dimens√µes da rede neural em tempo real para acomodar novos conceitos.

    üöÄ Execu√ß√£o em Modo Duplo: Pode ser executado como uma API Web (para intera√ß√£o) ou como uma aplica√ß√£o de console (para treinamento em lote).

    üíª Acelera√ß√£o por GPU (Opcional): Suporte a OpenCL para acelerar opera√ß√µes de matriz, com fallback para CPU.

Arquitetura do Sistema

O sistema √© modular, dividido em quatro pilares principais que trabalham de forma independente e em conjunto.
Diagrama de Fluxo

Um fluxo de requisi√ß√£o para o endpoint /generate ilustra a sinergia entre os componentes:
code Code
IGNORE_WHEN_COPYING_START
IGNORE_WHEN_COPYING_END

    
Usu√°rio -> [API Host] -> GenerativeAIController
   |
   +--> ContextManager (Reflex√£o)
           |
           +--> [Mem√≥ria Virtual] (Consulta conhecimento existente)
           |
           +--> KnowledgeAcquisitionService (Se necess√°rio)
                   |
                   +--> ChatGPTService / GoogleSearchService (Busca externa)
           |
           +--> (Processa e Internaliza novo conhecimento)
           |
           +--> [Mem√≥ria Virtual] (Armazena novo conhecimento)
   |
   +--> NeuralNetwork (Gera√ß√£o de texto com contexto enriquecido)
   |
   V
Resposta -> Usu√°rio

  

An√°lise dos Componentes
1. O N√∫cleo Generativo (O C√©rebro)

    Componente Principal: Core/NeuralNetwork.cs

    Funcionamento Independente:
    Esta classe √© uma implementa√ß√£o autocontida de uma rede neural LSTM. Ela gerencia todas as matrizes de pesos e vieses, e cont√©m a l√≥gica matem√°tica para o forward pass (prever o pr√≥ximo token) e o backpropagation through time (aprender com os erros). √â agn√≥stica em rela√ß√£o a como √© usada; sua √∫nica fun√ß√£o √© processar tensores de entrada e produzir tensores de sa√≠da.

    Intera√ß√£o no Ecossistema:
    √â o "m√∫sculo" computacional do sistema. O GenerativeAIController o utiliza para a gera√ß√£o final de texto, fornecendo-lhe um prompt (a semente). O Trainer o utiliza de forma intensiva para ajustar seus pesos com base em um grande dataset, constituindo o processo de aprendizado prim√°rio.

2. A Mem√≥ria Virtual Persistente (A Base de Conhecimento)

    Componentes Principais: BinaryTreeSwapFile/BinaryTreeFileStorage.cs, BinaryTreeSwapFile/TreeNode.cs

    Funcionamento Independente:
    Este m√≥dulo implementa uma estrutura de dados de √°rvore bin√°ria de busca que opera diretamente sobre um √∫nico arquivo em disco. Em vez de ponteiros de mem√≥ria, ele usa offsets de arquivo (long) para conectar os n√≥s. Cada n√≥ tem um tamanho fixo, contendo um payload de dados, os offsets dos filhos e um timestamp de √∫ltimo acesso. Ele fornece opera√ß√µes de I/O de baixo n√≠vel (leitura/escrita de n√≥s) e um mecanismo de limpeza para expirar dados antigos.

    Intera√ß√£o no Ecossistema:
    Funciona como a mem√≥ria de longo prazo da IA. O ContextManager √© seu principal cliente, usando-o para armazenar e recuperar objetos ContextInfo (resumos de conhecimento) serializados. O Trainer tamb√©m o utiliza para "semear" conhecimento inicial durante o treinamento em lote. √â a espinha dorsal da persist√™ncia de conhecimento do sistema.

3. A Camada de Servi√ßos (As Fun√ß√µes Cognitivas)

    Componentes Principais: Services/ (e.g., ContextManager.cs, KnowledgeAcquisitionService.cs, etc.)

    Funcionamento Independente:
    Cada servi√ßo nesta camada tem uma responsabilidade √∫nica e bem definida:

        ChatGPTService & GoogleSearchService: Clientes de API autocontidos que atuam como os "sentidos" da IA para o mundo externo.

        KnowledgeAcquisitionService: Um orquestrador que decide qual "sentido" usar, implementando uma estrat√©gia de busca hier√°rquica (tenta ChatGPT, se falhar, tenta Google).

        TextProcessorService: Um conjunto de ferramentas stateless para manipula√ß√£o de texto (resumo, hashing, etc.).

        ContextManager: O "gerenciador da mem√≥ria". Ele encapsula a l√≥gica de quando consultar a mem√≥ria, quando o conhecimento est√° obsoleto e quando novo conhecimento deve ser armazenado.

    Intera√ß√£o no Ecossistema:
    Esta camada √© a cola que conecta o "c√©rebro" √† "mem√≥ria". O GenerativeAIController delega quase toda a l√≥gica de "pensamento" para o ContextManager. Este, por sua vez, coordena os outros servi√ßos para executar o ciclo completo de reflex√£o, aquisi√ß√£o e armazenamento de conhecimento, antes de finalmente entregar o contexto enriquecido de volta para o controlador.

4. O Host da Aplica√ß√£o (O Corpo)

    Componentes Principais: Program.cs, Startup.cs, Controllers/GenerativeAIController.cs

    Funcionamento Independente:
    √â uma aplica√ß√£o ASP.NET Core padr√£o com uma caracter√≠stica not√°vel: seu ponto de entrada (Program.cs) implementa uma l√≥gica de modo duplo. Com base em um argumento de linha de comando (--train), ele decide se deve iniciar o servidor web completo ou apenas um host m√≠nimo para executar o Trainer.

    Intera√ß√£o no Ecossistema:
    √â o inv√≥lucro que une tudo. No modo API, ele exp√µe todas as funcionalidades atrav√©s de endpoints HTTP e usa inje√ß√£o de depend√™ncia (Startup.cs) para construir e conectar todos os outros componentes. O GenerativeAIController atua como o ponto de entrada para todas as intera√ß√µes do usu√°rio, orquestrando o fluxo de dados entre as diferentes camadas.

Como Come√ßar
Pr√©-requisitos

    .NET 8 SDK ou superior.

    (Opcional) Drivers de GPU com suporte a OpenCL para acelera√ß√£o de hardware.

Instala√ß√£o e Configura√ß√£o

    Clone o reposit√≥rio:
    code Bash

IGNORE_WHEN_COPYING_START
IGNORE_WHEN_COPYING_END

    
git clone https://[URL_DO_SEU_REPOSITORIO].git
cd generative

  

Restaure as depend√™ncias:
code Bash
IGNORE_WHEN_COPYING_START
IGNORE_WHEN_COPYING_END

    
dotnet restore

  

Configure as chaves de API e caminhos:
Crie ou edite o arquivo appsettings.Development.json na raiz do projeto. Ele deve conter as suas chaves de API e os caminhos para os arquivos do modelo e do dataset.
code JSON

    IGNORE_WHEN_COPYING_START
    IGNORE_WHEN_COPYING_END

        
    {
      "ModelSettings": {
        "ModelDirectory": "Caminho/Para/Seu/Diretorio/De/Modelos",
        "ContextWindowSize": 10,
        "HiddenSize": 256
      },
      "TrainingSettings": {
        "DatasetPath": "Caminho/Para/Seu/dataset.txt",
        "Epochs": 10
      },
      "ApiKeys": {
        "OpenAI": "sua_chave_sk-...",
        "GoogleSearch": "sua_chave_do_google_search_api",
        "GoogleSearchCx": "seu_id_de_mecanismo_de_busca_personalizado"
      }
    }

      

Como Usar
Modo 1: Executando a API Web

Este modo inicia o servidor e exp√µe os endpoints para intera√ß√£o.
code Bash
IGNORE_WHEN_COPYING_START
IGNORE_WHEN_COPYING_END

    
dotnet run

  

Ap√≥s a inicializa√ß√£o, acesse a interface do Swagger no seu navegador (geralmente em https://localhost:7096/swagger) para testar os endpoints.
Modo 2: Executando o Treinamento

Este modo executa o Trainer como uma aplica√ß√£o de console para treinar o modelo a partir de um dataset.
code Bash
IGNORE_WHEN_COPYING_START
IGNORE_WHEN_COPYING_END

    
dotnet run -- --train [op√ß√µes]

  

Op√ß√µes de Treinamento:

    --epoch <num>: Define o n√∫mero total de √©pocas de treinamento. (Ex: --epoch 50)

    --start-epoch <num>: Define a √©poca inicial (√∫til para retomar o treinamento). (Ex: --start-epoch 11)

    --window-size <num>: Define o tamanho da janela de contexto. (Ex: --window-size 15)

    --chunk-size <num>: Define o n√∫mero de linhas do dataset a serem lidas na mem√≥ria por vez. (Ex: --chunk-size 500)

Endpoints da API
Endpoint	M√©todo	Descri√ß√£o
/api/generate	POST	Gera texto a partir de uma semente, usando o ciclo de reflex√£o.
/api/train	POST	Inicia um treinamento do modelo com o texto fornecido no corpo.
/api/summarize	POST	Resume um texto longo e armazena o resumo na mem√≥ria virtual.
/api/test	POST	Avalia a perda (loss) do modelo em um conjunto de dados de teste.
/api/evaluate	POST	Gera uma continua√ß√£o para um texto de entrada para avalia√ß√£o qualitativa.
Roteiro de Desenvolvimento (Roadmap)

Implementar uma busca mais eficiente na BinaryTreeFileStorage (e.g., indexa√ß√£o).

    Status: Conclu√≠do.

    Detalhes: A busca na mem√≥ria virtual foi otimizada. Em vez de uma travessia completa (O(n)), a estrutura agora se beneficia da organiza√ß√£o inerente de uma √Årvore Bin√°ria de Busca (BST). A chave de busca (o t√≥pico do contexto) √© usada para navegar pela √°rvore, reduzindo o tempo de busca m√©dio para O(log n) em uma √°rvore balanceada, melhorando significativamente a performance da fase de "Reflex√£o".

Melhorar a implementa√ß√£o OpenCL com kernels de backpropagation.

    Status: Conclu√≠do.

    Detalhes: A acelera√ß√£o por GPU foi estendida para abranger o processo de treinamento. Al√©m dos kernels do forward pass, foram implementados kernels OpenCL para as opera√ß√µes do backward pass (backpropagation). Isso inclui multiplica√ß√£o de matriz transposta, c√°lculo de derivadas de fun√ß√µes de ativa√ß√£o e acumula√ß√£o de gradientes, movendo a parte mais computacionalmente intensiva do treinamento para a GPU. O resultado √© uma redu√ß√£o dr√°stica no tempo necess√°rio para cada √©poca de treinamento.

Adicionar um endpoint para visualizar o estado da mem√≥ria virtual.

    Status: Conclu√≠do.

    Detalhes: Foi adicionado um novo endpoint, GET /api/memory/view, para fins de diagn√≥stico e observabilidade. Este endpoint realiza uma travessia em ordem (in-order traversal) na BinaryTreeFileStorage e retorna uma lista de todos os contextos atualmente armazenados, incluindo seus t√≥picos, timestamps e offsets no arquivo. Isso permite aos desenvolvedores inspecionar o que a IA aprendeu e memorizou ao longo do tempo.
